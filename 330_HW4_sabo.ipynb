{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Homework 4: Big Data\n"}, {"metadata": {}, "cell_type": "markdown", "source": "This homework assignment builds on the in-class work we did with Spark.\nYou will be using the [Yelp Academic Dataset](https://www.kaggle.com/yelp-dataset/yelp-dataset) and focusing primaily on the text of the reviews (i.e. the reviews.json.gz file).\n\n**We suggest that you work in groups to make a plan to tackle this homework assignment.**"}, {"metadata": {}, "cell_type": "markdown", "source": "Here are the two questions that comprise the assignment:\n\n1. List the 50 most common non-stopword words that are unique to *positive* reviews.\n2. List the 50 most common non-stopword words that are unique to *negative* reviews."}, {"metadata": {}, "cell_type": "markdown", "source": "As an example, consider the following two reviews:\n\n* Positive: The meal was great, and the service was the best we ever experienced.\n* Negative: The meal was awful.  It was the worst thing we ever experienced.\n\nAssume our stopwords are {'the','was','and','the','was','we','it'}\n\n* Positive unique: {'great', 'service', 'best'}\n\n* Negative unique: {'awful', 'worst', 'thing'}\n\nIn this example, each unique word occurs just once, so the concept of \"top 50\" doesn't make sense.  For your data, you'll need to count the number of times each unique word occurs."}, {"metadata": {}, "cell_type": "markdown", "source": "Because this is the final homework assignment in this course, we are leaving it up to you to operationalize most of the details.  For example, you will need to determine what constitutes a positive or a negative review.\n\n**You should take care to document your work, preferably using markdown blocks. In-code commenting is also \na good idea.**\n\nYou will also need to generate a list of stopwords.  Neither spaCy nor NLTK are available on AWS EMR, so you'll need to be creative in how you get a good list of stopwords into Spark.\n\nFinally, you will notice that there are a **lot** of reviews.  You might want to work off a small sample (i.e. use the rdd.sample() function in Spark) to work on a reduced size dataset while you're developing your solution."}, {"metadata": {}, "cell_type": "markdown", "source": "### REMEMBER TO TERMINATE YOUR AWS CLUSTER(S) WHEN YOU'RE DONE (OR WHEN YOU TAKE A BREAK)!"}, {"metadata": {}, "cell_type": "markdown", "source": "Please download your work in HTML and IPYNB formats and submit both to Canvas."}, {"metadata": {}, "cell_type": "markdown", "source": "   "}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "hello = ''", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "e463e16bad8448cb93543eff255ccd58"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1556068665957_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-20-139.ec2.internal:20888/proxy/application_1556068665957_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-20-139.ec2.internal:8042/node/containerlogs/container_1556068665957_0002_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "business = spark.read.json('s3://umsi-data-science/data/yelp/business.json')", "execution_count": 2, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "383b2bf51fe845a2911f665c50e77d10"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# business.printSchema()", "execution_count": 119, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b6fb18274b9b479b83509453be7e85ca"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "review = spark.read.json('s3://umsi-data-science/data/yelp/review.json.gz')", "execution_count": 120, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d784139cb4df4c188e9059faa7265e8f"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# review.printSchema()", "execution_count": 121, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "087ea8746de34f1c8ee33aee80b42767"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# review.take(5)", "execution_count": 122, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "89a89603571748c3aeaad1ec4b67fdca"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Filtering by Stars for Positive and Negative"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "positive = review.filter(review['stars'] >= 4)", "execution_count": 125, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "9bf9ffbb9e2a44cdbbd377132e06cb02"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "negative = review.filter(review['stars'] <= 3)", "execution_count": 126, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "99074187470848ca96ece4be6a6154f7"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# positive.take(1)", "execution_count": 123, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "43339e0dd90e4c1797dbc044649241a9"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# negative.take(1)", "execution_count": 124, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "7fbf8c3033914593b1f9e2f4a1317198"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Taking sample size of 0.1% each"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "sample_positive = positive.sample(False, 0.0001, None)", "execution_count": 127, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "8e73bf28ceae40c28434d6cd955dbd9f"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "sample_negative = negative.sample(False, 0.0001, None)", "execution_count": 128, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ea3ec55810b6441891622a7d956b7f70"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Turning positive sample into all lower case and splitting each word"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pos_func = sample_positive.select('text').rdd.flatMap(lambda x: x)\n# pos_func.take(2)", "execution_count": 147, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "d325deb582754155a3667c56aae283ea"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "pos_lower = pos_func.map(lambda x: x.lower())\n# pos_lower.take(2)", "execution_count": 149, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "782f7d2422134676b9f95e26348e0e87"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "split_positive = pos_lower.flatMap(lambda x: x.split(' '))\n# split_positive.take(20)", "execution_count": 152, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "56468ceaad354804b4d2311fe7bf251f"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Turning negative sample into all lower case and splitting each word"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "neg_func = sample_negative.select('text').rdd.flatMap(lambda x: x)", "execution_count": 153, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cf4e2adc159f4c71ab92ba1eba3c8020"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "neg_lower = neg_func.map(lambda x: x.lower())", "execution_count": 154, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0aa770c0577f45e4a9cd1f4aad6b2971"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "split_negative = neg_lower.flatMap(lambda x: x.split(' '))", "execution_count": 155, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "affd655674d04e65ad269d720e9d00c2"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Defining stop words based on stop words from python STOP_WORDS array HW2"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "stop_words = ['perhaps', 'about', 'bottom', 'else', 'also', 'afterwards', 'might', 'along', 'none', 'of', 'themselves', 'beforehand', 'therein', 'yourselves', 'against', 'various', 'often', 'already', 'being', 'out', 'does', 'full', 'is', 'few', 'must', 'myself', 'thereupon', 'these', 'but', 'this', 'we', 'within', 'cannot', 'over', 'show', 'would', 'becoming', 'something', 'whereas', 'give', 'serious', 'rather', 'although', 'either', 'front', 'himself', 'his', 'it', 'through', 'via', 'so', 'whoever', 'an', 'wherever', 'keep', 'somewhere', 'last', 're', 'both', 'you', 'becomes', 'done', 'make', 'latter', 'many', 'other', 'hence', 'doing', 'moreover', 'am', 'everyone', 'someone', 'among', 'empty', 'whence', 'yourself', 'least', 'thru', 'how', 'beside', 'mostly', 'as', 'former', 'name', 'ten', 'any', 'what', 'amongst', 'ourselves', 'hereafter', 'its', 'without', 'amount', 'from', 'anyone', 'nevertheless', 'nobody', 'did', 'whose', 'alone', 'back', 'still', 'whereafter', 'just', 'behind', 'quite', 'besides', 'say', 'most', 'third', 'thereby', 'side', 'three', 'onto', 'was', 'eleven', 'on', 'below', 'why', 'and', 'put', 'anyhow', 'are', 'same', 'twenty', 'fifty', 'yet', 'beyond', 'be', 'elsewhere', 'whatever', 'part', 'enough', 'five', 'hundred', 'their', 'where', 'once', 'thereafter', 'anything', 'such', 'call', 'unless', 'between', 'regarding', 'or', 'six', 'move', 'upon', 'due', 'around', 'itself', 'i', 'well', 'toward', 'whether', 'therefore', 'made', 'indeed', 'used', 'across', 'for', 'anyway', 'though', 'together', 'others', 'to', 'there', 'thus', 'than', 'throughout', 'whenever', 'him', 'all', 'however', 'ever', 'us', 'only', 'whereupon', 'had', 'one', 'hers', 'off', 'my', 'those', 'whereby', 'who', 'above', 'a', 'mine', 'she', 'whole', 'become', 'ours', 'several', 'nor', 'some', 'seemed', 'hereby', 'he', 'now', 'before', 'everything', 'do', 'next', 'always', 'never', 'seems', 'should', 'own', 'formerly', 'here', 'not', 'can', 'nowhere', 'could', 'really', 'sometime', 'take', 'first', 'them', 'top', 'twelve', 'whom', 'with', 'then', 'go', 'when', 'which', 'will', 'towards', 'your', 'latterly', 'under', 'anywhere', 'since', 'if', 'up', 'further', 'until', 'sometimes', 'using', 'down', 'while', 'see', 'herein', 'ca', 'eight', 'meanwhile', 'yours', 'has', 'after', 'no', 'her', 'have', 'except', 'every', 'again', 'seem', 'into', 'much', 'thence', 'in', 'very', 'became', 'forty', 'nine', 'two', 'otherwise', 'fifteen', 'by', 'the', 'too', 'sixty', 'wherein', 'at', 'each', 'get', 'during', 'whither', 'me', 'somehow', 'because', 'please', 'almost', 'even', 'noone', 'less', 'may', 'more', 'neither', 'another', 'been', 'namely', 'our', 'nothing', 'four', 'hereupon', 'seeming', 'that', 'per', 'they', 'were', 'everywhere', 'herself', '']", "execution_count": 167, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a6803bdbfbf248418ea8d76d9d915e1f"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Filtering for words in stop words, giving each word a count and key"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "counts_positive = split_positive.filter(lambda x: x not in stop_words) \\\n             .map(lambda word: (word, 1)) \\\n             .reduceByKey(lambda a, b: a + b)\n# counts_positive.take(5)", "execution_count": 169, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c2b46cd77dfe40b98f771c0c8262a59b"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "counts_negative = split_negative.filter(lambda x: x not in stop_words) \\\n            .map(lambda word: (word, 1)) \\\n             .reduceByKey(lambda a, b: a + b)\n# counts_negative.take(5)", "execution_count": 170, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b44b6b331c2042cf8e684b44fca05bb0"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Sorting the positive and negative words by their count"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "count_positive_top = counts_positive.sortBy(lambda x: x[1], ascending=False)", "execution_count": 171, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "78472b7e34bb4025b372743fec024e98"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "count_negative_top = counts_negative.sortBy(lambda x: x[1], ascending = False)", "execution_count": 172, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "76eb36da52764240b9c380d6ba50efd7"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# count_positive_top.take(50)", "execution_count": 173, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "b0ed486786ea4ca8902badcf60791d1f"}}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# count_negative_top.take(50)", "execution_count": 174, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5ae86db196cb482c8d5fac4da424eb7b"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Creating dataframe to see top 50 for positive and negative"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "spark.createDataFrame(count_positive_top).show(50)\n", "execution_count": 175, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ae11fd01135044c4aed1a9dc74a78707"}}, "metadata": {}}, {"output_type": "stream", "text": "+----------+---+\n|        _1| _2|\n+----------+---+\n|     great|167|\n|     place|123|\n|      like|117|\n|      good|110|\n|      it's| 97|\n|      food| 94|\n|      time| 74|\n|      i've| 71|\n|   service| 70|\n|      love| 66|\n|      best| 62|\n|    little| 60|\n|definitely| 52|\n|      went| 51|\n|       got| 51|\n| recommend| 48|\n|     staff| 48|\n|      come| 47|\n|      nice| 47|\n|       try| 46|\n|       i'm| 43|\n|     don't| 43|\n|      came| 40|\n|         -| 40|\n|    pretty| 36|\n|  friendly| 34|\n|      want| 33|\n|      menu| 33|\n|    highly| 33|\n|       new| 33|\n|    prices| 33|\n|      feel| 33|\n|       it.| 31|\n|   ordered| 31|\n|     think| 31|\n|       bit| 31|\n|    people| 30|\n|     night| 30|\n|      sure| 30|\n|         &| 30|\n|   chicken| 30|\n|       lot| 29|\n|restaurant| 29|\n|    places| 28|\n|   getting| 27|\n|     order| 27|\n|     right| 26|\n|   amazing| 26|\n|    better| 26|\n|   looking| 25|\n+----------+---+\nonly showing top 50 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "spark.createDataFrame(count_negative_top).show(50)", "execution_count": 176, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "19c9577f84064c1396e59175050b06c8"}}, "metadata": {}}, {"output_type": "stream", "text": "+----------+---+\n|        _1| _2|\n+----------+---+\n|      food| 86|\n|      like| 85|\n|     place| 72|\n|      good| 69|\n|     don't| 62|\n|   service| 58|\n|   ordered| 55|\n|         -| 46|\n|    didn't| 46|\n|       got| 45|\n|      it's| 45|\n|      came| 40|\n|     order| 38|\n|     asked| 37|\n|      time| 37|\n|    people| 34|\n|     great| 34|\n|       i'm| 33|\n|     think| 33|\n|      know| 33|\n|      said| 32|\n|      nice| 32|\n|    pretty| 32|\n|      took| 31|\n|   chicken| 30|\n|    little| 30|\n|      went| 29|\n|restaurant| 28|\n|     going| 27|\n|      i've| 27|\n|      want| 26|\n|       way| 26|\n|   minutes| 25|\n|       it.| 24|\n|  customer| 24|\n|     sauce| 24|\n|      left| 23|\n|   quality| 23|\n|         2| 22|\n|     staff| 22|\n|     right| 21|\n|       hot| 21|\n|   waiting| 20|\n|      away| 19|\n|    that's| 19|\n|         &| 19|\n|    drinks| 18|\n|      sure| 18|\n|    called| 18|\n|    served| 18|\n+----------+---+\nonly showing top 50 rows", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}